{
    "version": "0.9.33",
    "description": "Run LLMs on AMD Ryzen AI NPUs in minutes. Purpose-built and deeply optimized for AMD XDNA2 NPUs.",
    "homepage": "https://fastflowlm.com",
    "license": {
        "identifier": "MIT,Proprietary",
        "url": "https://github.com/FastFlowLM/FastFlowLM/blob/main/TERMS.md"
    },
    "url": "https://github.com/FastFlowLM/FastFlowLM/releases/download/v0.9.33/flm-setup.exe",
    "hash": "sha256:90870cdfe7d82a416160b5c4523ffa822792ac33966b1177a35490450102e3bf",
    "innosetup": true,
    "bin": "flm.exe",
    "checkver": {
        "github": "https://github.com/FastFlowLM/FastFlowLM"
    },
    "autoupdate": {
        "url": "https://github.com/FastFlowLM/FastFlowLM/releases/download/v$version/flm-setup.exe",
        "hash": {
            "url": "https://api.github.com/repos/FastFlowLM/FastFlowLM/releases/tags/v$version",
            "jsonpath": "$.assets[?(@.name=='flm-setup.exe')].digest"
        }
    },
    "notes": [
        "IMPORTANT REQUIREMENTS:",
        "- AMD Ryzen AI processor with XDNA2 NPU (Strix, Strix Halo, or Kraken series)",
        "- Windows 11 with latest updates",
        "- AMD NPU drivers installed",
        "",
        "QUICK START:",
        "  flm run llama3.2:1b    # Run in interactive mode",
        "  flm serve llama3.2:1b  # Start API server",
        "",
        "For more information: https://fastflowlm.com/docs",
        "For supported models: flm list"
    ]
}
